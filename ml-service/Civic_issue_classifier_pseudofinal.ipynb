{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08fff9d3",
   "metadata": {},
   "source": [
    "## ⚠️ IMPORTANT: Changes Made for TensorFlow 2.15.0 Compatibility\n",
    "\n",
    "This notebook has been updated to work with **TensorFlow 2.15.0 + Keras 2.15.0** (matching ml-service requirements).\n",
    "\n",
    "**Changes Made:**\n",
    "1. **Cell 2**: Added version verification to ensure TensorFlow 2.15.0 + Keras 2.15.0 is installed\n",
    "2. **Cell 2.7**: Updated model save path to ml-service directory: `E:\\My Programs\\smart-civic-system\\ml-service\\app\\models\\`\n",
    "3. **Cell 2.7**: Now saves model in both `.keras` and `.h5` formats\n",
    "4. **New Cell**: Added verification cell to test model loading\n",
    "\n",
    "**To retrain:**\n",
    "1. Ensure Python environment has TensorFlow 2.15.0 and Keras 2.15.0 installed\n",
    "2. Run all cells from top to bottom\n",
    "3. The model will be saved automatically to ml-service directory\n",
    "4. Restart ml-service with `python -m app.main` to use the new model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fbb7e9-a515-41bb-82e6-f87d8dd6ac3b",
   "metadata": {},
   "source": [
    "**BUILDING AN IMAGE CLASSIFIER WHICH CLASSIFIES IMAGES INTO SEVERAL CIVIC CATEGORIES LIKE GARBAGE, POTHOLES, ETC.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0028ef75-cf44-4aaa-b2c0-78c63696c3c4",
   "metadata": {},
   "source": [
    "**IMPORTING REQUIREMENTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04bc8ee-88a6-4ece-8f52-44a0c2399c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1dff5b-1a70-4746-abc3-7c4d6812ef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "Keras version: 2.15.0\n",
      "GPU available: []\n",
      "✅ Environment is compatible with ml-service (TensorFlow 2.15.0 + Keras 2.15.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\",keras.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Verify compatibility with ml-service\n",
    "assert tf.__version__.startswith('2.15'), f\"Use TensorFlow 2.15.0, you have {tf.__version__}\"\n",
    "assert keras.__version__.startswith('2.15'), f\"Use Keras 2.15.0, you have {tf.keras.__version__}\"\n",
    "print(\"✅ Environment is compatible with ml-service (TensorFlow 2.15.0 + Keras 2.15.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeca46b-35a7-44e6-a263-201e17826ce6",
   "metadata": {},
   "source": [
    "**CALLING DATA FROM FILES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43427b3-7933-4c1e-86b3-029c6778b6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24571 files belonging to 4 classes.\n",
      "Found 3374 files belonging to 4 classes.\n",
      "Found 2666 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"E:\\\\My Programs\\\\civic_issue_classification\\\\dataset\\\\train\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"E:\\\\My Programs\\\\civic_issue_classification\\\\dataset\\\\val\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"E:\\\\My Programs\\\\civic_issue_classification\\\\dataset\\\\test\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69bbaa6b-8d10-4257-ba67-b97c365fa59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['electricpoles', 'fallentrees', 'garbage', 'pothole']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4094d6-878b-4ee3-a782-e72784e00a9f",
   "metadata": {},
   "source": [
    "**NORMALIZATION AND AUGMENTATION OF DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5397abc-e074-43b7-bbbc-9f59385dd1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\My Programs\\smart-civic-system\\ml-service\\mlenv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# General augmentation for all classes\n",
    "general_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "# Stronger augmentation dedicated to garbage class\n",
    "# garbage_augmentation = tf.keras.Sequential([\n",
    "#     layers.RandomFlip(\"horizontal\"),\n",
    "#     layers.RandomRotation(0.2),\n",
    "#     layers.RandomZoom(0.2),\n",
    "#     layers.RandomContrast(0.2),\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e0a6e4f-468c-4b5f-98de-9ed2bc63ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .map(lambda x, y: (general_augmentation(x, training=True), y))\n",
    "    .map(lambda x, y: (normalization_layer(x), y))\n",
    "    .shuffle(1000)\n",
    "    # .prefetch(tf.data.AUTOTUNE)\n",
    "    .prefetch(1)\n",
    ")\n",
    "\n",
    "val_ds = (\n",
    "    val_ds\n",
    "    .map(lambda x, y: (normalization_layer(x), y))\n",
    "    # .cache()\n",
    "    # .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    .prefetch(1)\n",
    ")\n",
    "\n",
    "test_ds = (\n",
    "    test_ds\n",
    "    .map(lambda x, y: (normalization_layer(x), y))\n",
    "    # .cache()\n",
    "    # .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    .prefetch(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ea1db-3181-4e36-a3c1-821d6158dd05",
   "metadata": {},
   "source": [
    "**TRIED AUGMENTING(OVERSAMPLING) GARBAGE CLASS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78490a34-db96-411e-b415-87de16bf70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# garbage_ds = train_ds_raw.unbatch().filter(\n",
    "#     lambda x, y: tf.equal(tf.argmax(y), garbage_index)\n",
    "# )\n",
    "\n",
    "# garbage_ds = garbage_ds.batch(batch_size)\n",
    "# garbage_ds = garbage_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "# garbage_ds = garbage_ds.map(lambda x, y: (garbage_augmentation(x, training=True), y))\n",
    "\n",
    "# # Merge augmented garbage back\n",
    "# train_ds = train_ds.concatenate(garbage_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444c3e7-8ef7-49e3-8690-e3be03ff1eaa",
   "metadata": {},
   "source": [
    "**BUILDING MODEL AND USING TRANSFER LEARNING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75bb8d-867f-4392-ba55-f17ab3bf1411",
   "metadata": {},
   "source": [
    "**1. CUSTOM CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60d2d43-d639-469d-b70c-956c32c743f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_civic_cnn(input_shape=(224,224,3), num_classes=4):\n",
    "#     inputs = layers.Input(shape=input_shape)\n",
    "#     model = models.Sequential([\n",
    "#         layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "#         layers.MaxPooling2D((2,2)),\n",
    "\n",
    "#         layers.Conv2D(64, (3,3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2,2)),\n",
    "\n",
    "#         layers.Conv2D(128, (3,3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2,2)),\n",
    "\n",
    "#         layers.Conv2D(256, (3,3), activation='relu'),\n",
    "#         layers.MaxPooling2D((2,2)),\n",
    "\n",
    "#         #layers.Flatten(),\n",
    "#         layers.GlobalAveragePooling2D(),\n",
    "#         layers.Dense(128, activation='relu'),\n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(num_classes, activation='softmax')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# model = build_civic_cnn()\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83052fd-6be6-4d1a-b887-464e91343e75",
   "metadata": {},
   "source": [
    "**ADDING CLASS WEIGHTS AND MENTIONING CHECKPOINTS AND EARLYSTOP**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b417311-044d-450e-8883-c173d87aa9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24571 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# RAW training dataset (ONLY for class weights)\n",
    "train_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"E:\\\\My Programs\\\\civic_issue_classification\\\\dataset\\\\train\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2285163-7f83-4afd-b78e-64230d085154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.8448287718333104, 1: 0.7226764705882353, 2: 1.9606607085860197, 3: 1.083950944062114}\n"
     ]
    }
   ],
   "source": [
    "#Adding class weights so that the balance is maintained between classes\n",
    "# ===============================\n",
    "# CLASS WEIGHTS\n",
    "# ===============================\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "labels = []\n",
    "\n",
    "assert train_ds_raw is not None, \"train_ds_raw must be defined before computing class weights\"\n",
    "for _, y in train_ds_raw.unbatch():\n",
    "    if len(y.shape) > 0:          # one-hot\n",
    "        labels.append(int(np.argmax(y.numpy())))\n",
    "    else:                         # integer labels\n",
    "        labels.append(int(y.numpy()))\n",
    "\n",
    "unique_classes = np.arange(len(class_names))\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=unique_classes,\n",
    "    y=labels\n",
    ")\n",
    "\n",
    "class_weights = dict(zip(unique_classes, class_weights))\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "#*******************************************************************************\n",
    "#Calculating steps per epoch\n",
    "# train_steps = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "# steps_per_epoch = train_steps\n",
    "# print(\"Steps per epoch:\", steps_per_epoch)\n",
    "#*******************************************************************************\n",
    "\n",
    "# ===============================\n",
    "# CALLBACKS\n",
    "# ===============================\n",
    "#Checkpoint for saving the best model only \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True)\n",
    "\n",
    "#Earlystop to avoid over computation\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,            # stop if val_loss doesn’t improve for 2 epochs\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988bf75e-7b76-4d0f-be98-85fa1a0823ca",
   "metadata": {},
   "source": [
    "**1.1 FITTING MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a433016-d535-4455-a3d5-e2cab50f1470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=8,\n",
    "#     class_weight=class_weights,\n",
    "#     steps_per_epoch = steps_per_epoch,\n",
    "#     callbacks=[early_stop, checkpoint]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "587e1da3-d2d7-47a3-ab46-daaf63e87e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"civic_issue_model_customCNN.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1f8f8-a7b8-40f9-bcce-2b83200eb707",
   "metadata": {},
   "source": [
    "**1.2 PLOTTING THE LEARNINGS MADE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a53946a9-9623-40a5-b6e7-1caf04014aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['accuracy'], label='train acc')\n",
    "# plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history.history['loss'], label='train loss')\n",
    "# plt.plot(history.history['val_loss'], label='val loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f70e9-7c3d-42a7-977b-1d2629ce3574",
   "metadata": {},
   "source": [
    "**1.3 TESTING MODEL PERFORMANCE ON TEST_DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baeda934-98e3-4d95-b761-b0690b90d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(test_ds)   #testing model performance on the test data set\n",
    "# print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a729b69-70fd-4c8a-9689-b288ff57a972",
   "metadata": {},
   "source": [
    "**1.4 LET's TRY A DEMO IMAGE AND SEE HOW MODEL CLASSIFIES IT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20d692e5-f900-46ff-8b40-f7bb41fd849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# class_names = train_ds.class_names\n",
    "# print(\"Class names:\", class_names)\n",
    "\n",
    "# img_path = \"E:\\\\My Programs\\\\civic_issue_classification\\\\dataset\\\\train\\\\garbage\\\\1__aluminum-tin-cans-2_jpg.rf.3357c35942c2fcc9ec3ff705e89ed967.jpg\"  # replace with any test image\n",
    "# img = image.load_img(img_path, target_size=img_size)\n",
    "# img_array = image.img_to_array(img)/255.0\n",
    "# img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# pred = model.predict(img_array)\n",
    "# print(\"Predicted category:\", class_names[np.argmax(pred)])\n",
    "# print(\"Prediction probabilities:\", pred[0])  # show all 4 class probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "433da904-ee7f-4582-9c5b-30998a1770b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electricpoles 7271\n",
      "fallentrees 8500\n",
      "garbage 3133\n",
      "pothole 5667\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for cls in class_names:\n",
    "    print(cls, len(os.listdir(f\"E:\\\\My Programs\\\\civic_issue_classification\\\\dataset\\\\train\\\\{cls}\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd54a8b-9c50-4cdc-8cc3-f16465436b48",
   "metadata": {},
   "source": [
    "**1.5 PLOTTING CONFUSION MATRIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87543954-2ae2-439d-8974-47ffb197e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_true, y_pred = [], []\n",
    "# for images, labels in test_ds:\n",
    "#     preds = model.predict(images)\n",
    "#     y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "#     y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "# sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names, fmt='d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4415c-1288-4056-b71a-1743d684c467",
   "metadata": {},
   "source": [
    "**2. TRANSFER LEARNING MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaed609-c2c3-4f0f-b3b1-69f746bc56c7",
   "metadata": {},
   "source": [
    "**2.1 LOAD PRETRAINED MobileNetV2 (FEATURE EXTRACTOR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b189de07-db34-4d68-a450-f4fc3f671192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\My Programs\\smart-civic-system\\ml-service\\mlenv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "# Freeze pretrained weights\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ab64b-5c60-4f58-8d04-15bfd79c3884",
   "metadata": {},
   "source": [
    "**2.2 BUILDING TL MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fad6384-f671-49af-bf56-ee53e1b80a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(class_names), activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94728df2-a29b-4474-bbf2-4ac393b3ceb2",
   "metadata": {},
   "source": [
    "**2.3 COMPILING THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0e12946-df2e-4907-b54f-3dc4fbeae98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1280)              5120      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2427588 (9.26 MB)\n",
      "Trainable params: 167044 (652.52 KB)\n",
      "Non-trainable params: 2260544 (8.62 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86222977-8578-493a-80db-cc9e087adf81",
   "metadata": {},
   "source": [
    "**2.4 TRAINING THE MODEL (MODEL FIT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a58391-f199-45bb-a525-f766624c2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From E:\\My Programs\\smart-civic-system\\ml-service\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\My Programs\\smart-civic-system\\ml-service\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb72c655-8d0d-4060-a42d-715cc9415378",
   "metadata": {},
   "source": [
    "**2.5 TEST SET EVALUATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13419461-67d2-4a62-8f7c-b4bdf882ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_ds, return_dict=True)\n",
    "\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563d7cf-8929-4149-bfde-b96578cfa651",
   "metadata": {},
   "source": [
    "**2.6 REPRESENTING CONFUSION MATRIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1691a-cc3e-433c-9985-8b69546d701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "for x, y in test_ds:\n",
    "    preds = model.predict(x, verbose=0)\n",
    "    y_true.extend(np.argmax(y.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - MobileNetV2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910bb888-3734-47e7-baea-a334042f92e5",
   "metadata": {},
   "source": [
    "**2.7 SAVE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4583e521-8ab5-4764-9c53-e26beb2ef5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# SAVE BASELINE MOBILE NET MODEL TO ML-SERVICE\n",
    "# =====================================================\n",
    "\n",
    "# Save to ml-service directory\n",
    "ml_service_path = r\"E:\\My Programs\\smart-civic-system\\ml-service\\app\\models\"\n",
    "os.makedirs(ml_service_path, exist_ok=True)\n",
    "\n",
    "# Save both formats for compatibility\n",
    "keras_path = os.path.join(ml_service_path, \"image_classifier.keras\")\n",
    "h5_path = os.path.join(ml_service_path, \"image_classifier.h5\")\n",
    "\n",
    "model.save(keras_path)\n",
    "model.save(h5_path)\n",
    "\n",
    "print(f\"✅ Model saved to ml-service directory: {ml_service_path}\")\n",
    "print(f\"  - {keras_path}\")\n",
    "print(f\"  - {h5_path}\")\n",
    "\n",
    "assert os.path.exists(keras_path), \"Model save failed (keras)!\"\n",
    "assert os.path.exists(h5_path), \"Model save failed (h5)!\"\n",
    "print(\"✅ Both model formats saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d341d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# VERIFY MODEL CAN BE LOADED\n",
    "# =====================================================\n",
    "\n",
    "# Test loading the keras model\n",
    "test_model = tf.keras.models.load_model(keras_path)\n",
    "print(\"✅ Model loads successfully from keras format!\")\n",
    "\n",
    "# Test with a sample image from test set\n",
    "test_images, test_labels = next(iter(test_ds))\n",
    "test_pred = test_model.predict(test_images[0:1], verbose=0)\n",
    "predicted_class = class_names[np.argmax(test_pred)]\n",
    "print(f\"✅ Prediction works! Sample predicted class: {predicted_class}\")\n",
    "print(f\"   Confidence: {np.max(test_pred):.2%}\")\n",
    "print(\"\\n✅ Model is fully compatible with TensorFlow 2.15.0 + Keras 2.15.0!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62220b1c-9ab1-413d-9da5-4214da7b1a6e",
   "metadata": {},
   "source": [
    "**2.8 TRY ON A SAMPLE IMAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4708aaf3-db0c-4b1f-9564-672f78440c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load saved model\n",
    "model = tf.keras.models.load_model(\"mobilenetv2_baseline.keras\")\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5e126f4-cfaa-4022-9360-f7ced0f0216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Predicted class: fallentrees\n",
      "Confidence: 61.71%\n",
      "electricpoles: 37.71%\n",
      "fallentrees: 61.71%\n",
      "garbage: 0.58%\n",
      "pothole: 0.00%\n"
     ]
    }
   ],
   "source": [
    "class_names = ['electricpoles', 'fallentrees', 'garbage', 'pothole']\n",
    "\n",
    "img_path = r\"E:\\My Programs\\civic_issue_classification\\dataset\\sample_image(fallentrees).jpg\"\n",
    "\n",
    "img_size = (224, 224)\n",
    "\n",
    "img = image.load_img(img_path, target_size=img_size)\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0          # normalization\n",
    "img_array = np.expand_dims(img_array, axis=0)  # batch dimension\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "predicted_class = class_names[np.argmax(predictions)]\n",
    "confidence = np.max(predictions) * 100\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"Confidence:\", f\"{confidence:.2f}%\")\n",
    "\n",
    "for i, prob in enumerate(predictions[0]):\n",
    "    print(f\"{class_names[i]}: {prob*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87d952-06a1-49b8-b3f6-7ce7553112a0",
   "metadata": {},
   "source": [
    "**2.8 FINE-TUNE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac7db3-ff1e-4c9d-848d-85edc3ef7a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# FINE-TUNING (ADVANCED)\n",
    "# =====================================================\n",
    "\n",
    "# Unfreeze last 20 layers of MobileNetV2\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "history_finetune = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5f996-edc3-424b-9e1c-1b980c06125e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
